{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as rq\n",
    "import string\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cabecera navegador\n",
    "cabecera = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/77.0.3865.90 Safari/537.36\"}\n",
    "\n",
    "#Url sitio scraping\n",
    "url_base = \"https://www.amazon.es\"\n",
    "url_base_dp = url_base + \"/dp/\"\n",
    "\n",
    "#Página inicial con el resultado de la búsqueda de libros de fisica\n",
    "url_inicial=\"https://www.amazon.es/s/ref=lp_902503031_nr_n_4?fst=as%3Aoff&rh=n%3A599364031%2Cn%3A%21599365031%2Cn%3A902503031%2Cn%3A902508031&bbn=902503031&ie=UTF8&qid=1571919270&rnid=902503031\"\n",
    "\n",
    "#Abrimos sesion\n",
    "sesion=rq.Session()\n",
    "sesion.post(url_base, headers=cabecera)\n",
    "\n",
    "#Accedemos a las página inicial\n",
    "pagina = sesion.get(url_inicial, headers=cabecera)\n",
    "soup = BeautifulSoup(pagina.content)\n",
    "num_pagina = 1\n",
    "\n",
    "#Obtenemos número máximo de páginas de resultados\n",
    "texto_nmax =soup.find(id=\"pagn\")\n",
    "contador_max = texto_nmax.find_all('span')\n",
    "pagina_max = int(contador_max[7].get_text())\n",
    "\n",
    "\n",
    "#Creamos dataframe libros_df\n",
    "libros_df = pd.DataFrame(columns=('titulo', 'precio', 'sinopsis', 'formato', 'editor','coleccion', 'idioma', 'isbn'))\n",
    "\n",
    "#Función que extrae los atributos del libro que nos interesan\n",
    "def datos_libro(arg):\n",
    "    #Retardamos peticiones\n",
    "    t0 = time.time()\n",
    "    libro = sesion.get(arg, headers=cabecera)\n",
    "    response_delay = time.time() - t0\n",
    "    time.sleep(10 * response_delay)\n",
    "    #Accedemos al contenido de la página\n",
    "    soup_libro = BeautifulSoup(libro.content)\n",
    "    reg_libro = []\n",
    "    #Accedemos al titulo\n",
    "    reg_libro.append(soup_libro.title.get_text().strip())\n",
    "    #Accedemos al precio\n",
    "    precio_libro =  soup_libro.find(id=\"buyNewSection\")\n",
    "    if precio_libro == None:\n",
    "        reg_libro.append(\"\")\n",
    "    else:\n",
    "        reg_libro.append(precio_libro.get_text().strip('\\n'))\n",
    "    #Accedemos a la sinopsis\n",
    "    sinopsis=soup_libro.find(id=\"bookDescription_feature_div\")\n",
    "    if sinopsis == None:\n",
    "        reg_libro.append(\"\")\n",
    "    else:\n",
    "        reg_libro.append(sinopsis.div)\n",
    "    #Accedemos detalle libro\n",
    "    detalle_libro=soup_libro.find(id=\"detail_bullets_id\")\n",
    "    if detalle_libro == None:\n",
    "        reg_libro.append([\"\", \"\", \"\", \"\", \"\"])\n",
    "    else:\n",
    "        detalle = detalle_libro.find_all('li')\n",
    "        formato = detalle[0].get_text().strip()\n",
    "        reg_libro.append(formato)\n",
    "        editor = detalle[1].get_text().strip()\n",
    "        reg_libro.append(editor)\n",
    "        coleccion=detalle[2].get_text().strip()\n",
    "        reg_libro.append(coleccion)\n",
    "        idioma = detalle[3].get_text().strip()\n",
    "        reg_libro.append(idioma)\n",
    "        isbn = detalle[5].get_text().strip()\n",
    "        reg_libro.append(isbn)\n",
    "    return reg_libro\n",
    "        \n",
    "\n",
    "#Recorremos las paginas resultados\n",
    "for paginas in range(pagina_max):\n",
    "\n",
    "    if num_pagina == 1:\n",
    "        resultado = soup.find(id=\"mainResults\")\n",
    "        for tag_li in resultado.find_all('li'):\n",
    "            asin = tag_li.get('data-asin')\n",
    "            #Edicion física\n",
    "            if asin[0] != 'B':\n",
    "                url = url_base_dp+asin+\"/\"\n",
    "                libro_amazon = datos_libro(url)\n",
    "                libros_df.loc[len(libros_df)]=libro_amazon\n",
    "                \n",
    "        url_pag_sig = soup.find(id=\"pagnNextLink\")\n",
    "        url_pag_sig = url_base + url_pag_sig.get(\"href\")\n",
    "        num_pagina = num_pagina + 1\n",
    "    else:\n",
    "        pagina = sesion.get(url_pag_sig, headers=cabecera)\n",
    "        soup = BeautifulSoup(pagina.content)\n",
    "        tag_div = soup.find_all('div')\n",
    "        for item in tag_div:\n",
    "            if item.has_attr('data-asin'):\n",
    "                asin = item.get('data-asin')\n",
    "                #Edicion física\n",
    "                if asin[0] != 'B':\n",
    "                    url = url_base_dp+asin+\"/\"\n",
    "                    libro_amazon = datos_libro(url)\n",
    "                    libros_df.loc[len(libros_df)]=libro_amazon\n",
    "        if num_pagina < pagina_max:\n",
    "            partes_url = url_pag_sig.split(\"&\")\n",
    "            url_0 = partes_url[0]\n",
    "            pagina = 'page='+ str(num_pagina+1)\n",
    "            url_2 = partes_url[2]\n",
    "            ref = 'ref=lp_902508031_pg_' + str(num_pagina)\n",
    "            url_pag_sig = url_0 + '&' + pagina + '&' + url_2 +'&' + ref\n",
    "            num_pagina = num_pagina + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "libros_df.to_csv('librosFisicaAmazon.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
